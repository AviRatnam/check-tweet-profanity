{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Profanity Checker.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyX0bp58kC4Y"
      },
      "source": [
        "# **Check Profanity of Tweet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFtG_g-BkQpQ"
      },
      "source": [
        "In this code we are checking the degree of profanity for a given tweet.\n",
        "In this approach, we will see the number of slur words to the total number of words in the tweet. \n",
        "Another key aspect we will keep in mind is that not all slurs are equal, some are much worse/ offensive than others. \n",
        "Hence, keeping that in mind, we will assign a degree of profanity to each slur as well. \n",
        "Hence a tweet such as 'You are sh* t' will be flagged for profanity, but with not as high a score as a tweet like 'You are a f*******' will be marked with a higher score, even though they both have only 1 slur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSeapjU6osXP",
        "outputId": "da9e9845-a299-43a9-e879-ea23fd66d694"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYcXbyXQjH1k"
      },
      "source": [
        "#list of slurs assuming slur1 < slur2 .... < slur5 in degree of profanity\n",
        "slurs = {\n",
        "         'slur1':0.1,\n",
        "         'slur2':0.25,\n",
        "         'slur3':0.5,\n",
        "         'slur4':0.75,\n",
        "         'slur5':0.9\n",
        "         }\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4UhmzTAmKQ0",
        "outputId": "16097000-7d67-41b2-b469-3e1787643905"
      },
      "source": [
        "#list of tweets\n",
        "\n",
        "tweets = {\n",
        "    \"userA\":\"Hello there, General Kenobi!\",\n",
        "    \"userB\":\"Yeah, @randomuser is a real slur3!\",\n",
        "    \"userC\":\"Go slur1 yourself @randomuser!! You're slur2ing this country!!\",\n",
        "    \"userD\":\"Lovely day for a cup of tea, slur5?\",\n",
        "    \"userE\":\"I am Iron Man slur1s!!!!!\",\n",
        "    \"userF\":\"This sentence is clean I promise\",\n",
        "    \"userG\":\"slur5 slur5 slur5 slur5 slur5 slur5 slur5\"\n",
        "    }\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'userA': 'Hello there, General Kenobi!', 'userB': 'Yeah, @randomuser is a real slur3!', 'userC': \"Go slur1 yourself @randomuser!! You're slur2ing this country!!\", 'userD': 'Lovely day for a cup of tea, slur5?', 'userE': 'I am Iron Man slur1s!!!!!', 'userF': 'This sentence is clean I promise', 'userG': 'slur5 slur5 slur5 slur5 slur5 slur5 slur5'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1EmguCfqhno"
      },
      "source": [
        "# **Calculating Score**\n",
        "From a range of 0-1, with 0.0 being a clean sentence and 1 being the worst possible tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeOCn6gTnHlu",
        "outputId": "ea7cacaa-3003-45b9-924a-fdb29d2570ca"
      },
      "source": [
        "m_arr=[\"(.*?)ing$\",\"(.*?)\\'s$\",\"(.*?)s$\"]\n",
        "\n",
        "for i in tweets:\n",
        "  sum=0\n",
        "  words=tweets[i].split()\n",
        "  for j in word_tokenize(tweets[i]):\n",
        "    if j in slurs.keys():\n",
        "      temp = slurs[j]\n",
        "      sum+=temp\n",
        "    else:\n",
        "      for k in m_arr:\n",
        "        m=re.match(k, j)\n",
        "        if m:\n",
        "          if m.group(1) in slurs.keys():\n",
        "            temp = slurs[m.group(1)]\n",
        "            sum+=temp\n",
        "  avg=sum/len(words)\n",
        "  print(i,\":\",tweets[i])\n",
        "  print(\"Score: \",round(avg,3))\n",
        "  print(\"------\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "userA : Hello there, General Kenobi!\n",
            "Score:  0.0\n",
            "------\n",
            "userB : Yeah, @randomuser is a real slur3!\n",
            "Score:  0.083\n",
            "------\n",
            "userC : Go slur1 yourself @randomuser!! You're slur2ing this country!!\n",
            "Score:  0.044\n",
            "------\n",
            "userD : Lovely day for a cup of tea, slur5?\n",
            "Score:  0.113\n",
            "------\n",
            "userE : I am Iron Man slur1s!!!!!\n",
            "Score:  0.02\n",
            "------\n",
            "userF : This sentence is clean I promise\n",
            "Score:  0.0\n",
            "------\n",
            "userG : slur5 slur5 slur5 slur5 slur5 slur5 slur5\n",
            "Score:  0.9\n",
            "------\n"
          ]
        }
      ]
    }
  ]
}